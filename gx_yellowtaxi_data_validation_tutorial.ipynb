{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Data Connection\n",
    "Initial setup of Great Expectations and connection to our data source. This section covers:\n",
    "* Importing required libraries\n",
    "* Initializing the Great Expectations Data Context\n",
    "* Connecting to PostgreSQL database\n",
    "* Creating data assets and batch definitions\n",
    "* Verifying our setup with data preview\n",
    "\n",
    "*Note: This setup establishes the foundation for our data validation framework, ensuring we can access and process our yellow taxi trip data effectively.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Required Libraries\n",
    "Import Great Expectations core package and its expectations module for data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "import great_expectations.expectations as gxe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Great Expectations Data Context\n",
    "Create a Data Context in file mode to manage expectations, validations, and data sources locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line initializes a new Data Context in \"file\" mode, which stores all configurations and results locally. The following are the available Data Context types:\n",
    "\n",
    "- **File Data Context**: A persistent Data Context that stores metadata and configuration information as YAML files within a file system. It allows you to re-use previously configured Expectation Suites, Data Sources, and Checkpoints.\n",
    "\n",
    "- **Ephemeral Data Context**: A temporary Data Context that stores metadata and configuration information in memory. It will not persist beyond the current Python session, making it useful for data exploration without needing to save results.\n",
    "\n",
    "- **GX Cloud Data Context**: A Data Context that connects to a GX Cloud Account to retrieve and store metadata and configuration information. This allows sharing of Expectation Suites, Data Sources, and Checkpoints with your organization.\n",
    "\n",
    "For more details, refer to the [Great Expectations documentation](https://docs.greatexpectations.io/docs/core/set_up_a_gx_environment/create_a_data_context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either use existing GX config from ./gx or delete ./gx folder to create fresh configuration in working directory (recommended)\n",
    "context = gx.get_context(mode=\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the current Data Context configuration to verify settings\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to PostgreSQL Data Source\n",
    "Configure connection to PostgreSQL database and create a datasource for Great Expectations to use. This datasource will be used to access and validate the yellow taxi trip data.\n",
    "\n",
    "Note: For demonstration purposes, we're using a simple connection string with exposed credentials. In production environments, you should use secure credential management as described in the [Great Expectations documentation](https://docs.greatexpectations.io/docs/core/connect_to_data/sql_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_CONNECTION_STRING = \"postgresql+psycopg2://postgres:superpass@127.0.0.1:5450/postgres\"\n",
    "datasource_name = \"pg_datasource\"\n",
    "\n",
    "data_source = context.data_sources.add_postgres(\n",
    "    name=datasource_name, connection_string=PG_CONNECTION_STRING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify PostgreSQL Data Source Configuration\n",
    "Display the data source configuration to confirm successful connection and review the connection details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch a Data Source from the Data Context.\n",
    "data_source_name = \"pg_datasource\"\n",
    "data_source = context.data_sources.get(data_source_name)\n",
    "data_source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Asset (Table Data Asset)\n",
    "Create a data asset that represents our table in the data source. A data asset serves as a bridge between Great Expectations and your data, enabling validation and expectation management.\n",
    "\n",
    "*Note: Data assets in Great Expectations can be created from tables or queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a name for our data asset - this is how we'll refer to it in Great Expectations\n",
    "table_asset_name = \"yellowtaxi_data\"\n",
    "\n",
    "# Specify the actual table name in our PostgreSQL database\n",
    "table_name = \"yellow_tripdata\"\n",
    "\n",
    "# Create a table asset by linking our data asset name to the physical database table\n",
    "taxi_table_asset = data_source.add_table_asset(name=table_asset_name, table_name=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all assets from the datasource\n",
    "assets = context.fluent_datasources[datasource_name].assets\n",
    "\n",
    "# Print asset details in a more structured format\n",
    "print(\"Data Assets in '{}' datasource:\".format(datasource_name))\n",
    "for asset in assets:\n",
    "    print(f\"  â€¢ Asset Name: {asset.name}\")\n",
    "    print(f\"    Type: {type(asset).__name__}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Batch Definition (Whole Table)\n",
    "Define how we want to access and validate our data. A batch definition specifies the scope of data to be validated - in this case, we're creating a definition to validate the entire table at once.\n",
    "\n",
    "*Note: Batch definitions in Great Expectations can be configured in different ways:*\n",
    "- Whole table - validates all data in the table\n",
    "- Custom SQL query - validates specific data based on a query\n",
    "- Partitioned data - validates data split by time periods or other criteria\n",
    "\n",
    "*For our yellow taxi data validation, we're using the whole table approach as we want to validate all records.*\n",
    "\n",
    "For more information on batch definitions, refer to the [Great Expectations documentation](https://docs.greatexpectations.io/docs/core/connect_to_data/sql_data/#procedure-batch-definition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Data Asset from the Data Source using our previously defined asset name\n",
    "asset_name = \"yellowtaxi_data\"   \n",
    "data_asset = data_source.get_asset(asset_name)\n",
    "\n",
    "# Create a batch definition for the entire table\n",
    "# This defines how we want to process the data - in this case, the whole table at once\n",
    "fulltable_batch_name = \"yellowtaxi_full_table_batch\"\n",
    "full_table_batch_definition = data_asset.add_batch_definition_whole_table(\n",
    "    name=fulltable_batch_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Batch Definition Configuration\n",
    "Verify the batch definition settings to ensure it's correctly configured for our yellow taxi data table. This step helps confirm that Great Expectations understands how to access our data.\n",
    "\n",
    "*Note: Reviewing the batch definition shows us important metadata like:*\n",
    "* The batch identifier\n",
    "* The data asset it's associated with\n",
    "* The configuration for accessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and display the batch definition configuration\n",
    "batch_name = \"yellowtaxi_full_table_batch\"\n",
    "full_table_batch_definition = data_asset.get_batch_definition(batch_name)\n",
    "full_table_batch_definition  # Display the configuration details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview Batch Data\n",
    "Retrieve a batch of data using our batch definition and display the first few rows. This helps verify that we can successfully access our yellow taxi data and examine its structure.\n",
    "\n",
    "*Note: The `head()` function shows the first few rows of the data, allowing us to:*\n",
    "* Confirm data is being retrieved correctly\n",
    "* Review the column names and data types\n",
    "* Verify the data content matches our expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and preview the data batch\n",
    "batch = full_table_batch_definition.get_batch()\n",
    "batch.head()  # Display first few rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Expectations\n",
    "Create and configure data quality rules for our yellow taxi data. This section covers:\n",
    "* Creating an Expectation Suite as a container for our data quality rules\n",
    "* Defining specific expectations for data validation:\n",
    "  - Ensuring pickup dates are not null\n",
    "  - Validating passenger counts are within valid range (0-6)\n",
    "* Reviewing the configured expectations\n",
    "\n",
    "*Note: Expectations are the core concept in Great Expectations, acting as assertions that define what we expect from our data. Each expectation represents a specific data quality rule, and together they form an Expectation Suite that can be used repeatedly to validate our data.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Expectation Suite\n",
    "Initialize a new suite named 'yellowtaxi_data_suite' to store our data quality rules for the taxi dataset.\n",
    "\n",
    "*Note: This suite will contain our specific validation rules for pickup dates and passenger counts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Expectation Suite with a descriptive name\n",
    "suite_name = \"yellowtaxi_data_suite\"\n",
    "suite = gx.ExpectationSuite(name=suite_name)\n",
    "\n",
    "# Add the Expectation Suite to our Data Context\n",
    "# This makes it available for future validations\n",
    "suite = context.suites.add(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Data Quality Expectations\n",
    "Add two validation rules to our suite:\n",
    "* Pickup date validation - must not be null\n",
    "* Passenger count validation - must be between 0 and 6 passengers\n",
    "\n",
    "*Note: These rules help identify invalid trip records and unrealistic passenger counts.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add expectation: pickup_date should never be null\n",
    "# This is crucial for trip tracking and analysis\n",
    "suite.add_expectation(\n",
    "    gxe.ExpectColumnValuesToNotBeNull(column=\"pickup_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add expectation: passenger_count should be between 0 and 6\n",
    "# This reflects the typical capacity of a taxi\n",
    "suite.add_expectation(\n",
    "    gxe.ExpectColumnValuesToBeBetween(\n",
    "        column=\"passenger_count\",\n",
    "        min_value=0,\n",
    "        max_value=6\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Expectation Suite Configuration\n",
    "Examine the configured Expectation Suite to verify that our data quality rules were properly added and configured.\n",
    "\n",
    "*Note: Reviewing the suite details allows us to:*\n",
    "* Confirm all expectations were added correctly\n",
    "* View the complete set of data quality rules\n",
    "* Verify the configuration of each expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and display the Expectation Suite configuration\n",
    "suite_name = \"yellowtaxi_data_suite\"\n",
    "suite_details = context.suites.get(suite_name)\n",
    "print(suite_details)  # Display all expectations in the suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Validations\n",
    "Execute and verify our data quality checks against the yellow taxi dataset. This section covers:\n",
    "* Creating a Validation Definition to connect our data with expectations\n",
    "* Registering the validation definition in our context\n",
    "* Running the actual validation process\n",
    "* Reviewing validation results in summary format\n",
    "\n",
    "*Note: Validation is where we actually test our data against the expectations we defined. This process helps us identify any data quality issues by showing which expectations passed or failed, providing immediate feedback on our data's quality.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Validation Definition\n",
    "Configure a validation task named 'yellowtaxi_data_validation' that connects our:\n",
    "* Taxi data batch\n",
    "* Expectation Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Validation Definition that connects our data with our expectations\n",
    "validation_definition_name = \"yellowtaxi_data_validation\"\n",
    "\n",
    "validation_definition = gx.ValidationDefinition(\n",
    "    data=full_table_batch_definition,  # The data batch to validate\n",
    "    suite=suite,                       # The expectations to validate against\n",
    "    name=validation_definition_name     # Name for this validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Validation Definition to Context\n",
    "Register our validation definition with the Data Context to make it available for execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the validation definition to our Data Context\n",
    "# This makes it available for running validations\n",
    "validation_definition = context.validation_definitions.add(validation_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Validation Definition\n",
    "Verify that our validation definition was properly configured by retrieving and displaying its details from the context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and display the validation definition configuration\n",
    "validation_definition_name = \"yellowtaxi_data_validation\"\n",
    "validation_definition = context.validation_definitions.get(validation_definition_name)\n",
    "print(validation_definition)  # Display the configuration details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Validation\n",
    "Run the validation to check if our taxi data meets the defined expectations. Using 'SUMMARY' format to get a concise overview of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the validation and get results in summary format\n",
    "results = validation_definition.run(result_format=\"SUMMARY\")\n",
    "\n",
    "# Display the validation results\n",
    "print(results)  # Shows which expectations passed or failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Docs\n",
    "Configure and manage documentation sites for our validation results through:\n",
    "* Site configuration and storage settings\n",
    "* Management of Data Docs sites (listing, adding, removing)\n",
    "* Custom site setup for validation results\n",
    "\n",
    "*Note: Data Docs transform our technical validations into readable, shareable documentation that helps track and communicate data quality.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Data Docs Site\n",
    "Define storage location and structure:\n",
    "* Base directory: 'uncommitted/data_docs/local_site'\n",
    "* Site builder configuration\n",
    "* Storage backend settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory for storing Data Docs files\n",
    "base_directory = \"uncommitted/data_docs/local_site/\"\n",
    "\n",
    "# Configure the Data Docs site settings\n",
    "site_config = {\n",
    "    \"class_name\": \"SiteBuilder\",                                  # Handles site generation\n",
    "    \"site_index_builder\": {\"class_name\": \"DefaultSiteIndexBuilder\"},  # Creates site index\n",
    "    \"store_backend\": {\n",
    "        \"class_name\": \"TupleFilesystemStoreBackend\",             # Manages file storage\n",
    "        \"base_directory\": base_directory,                         # Where files are stored\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List Available Data Docs Sites\n",
    "Display currently configured documentation sites in our context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and display names of all configured Data Docs sites\n",
    "context.get_site_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Existing Data Docs Site\n",
    "Clean up previous site configuration to prepare for new setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the existing Data Docs site from our context\n",
    "context.delete_data_docs_site(site_name=\"yellowtaxi_data_validation_result_site\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add New Data Docs Site\n",
    "Register site 'yellowtaxi_data_validation_result_site' using our custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new Data Docs site to our context\n",
    "site_name = \"yellowtaxi_data_validation_result_site\"\n",
    "context.add_data_docs_site(\n",
    "    site_name=site_name,     # Name for our validation results site\n",
    "    site_config=site_config  # Using the configuration we defined earlier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Actions and Checkpoints\n",
    "Automate the validation workflow through Checkpoints and Actions. This section demonstrates:\n",
    "\n",
    "* Checkpoints: Reusable validation configurations that combine:\n",
    "  - What to validate (validation definitions)\n",
    "  - When to validate (triggers)\n",
    "  - What to do with results (actions)\n",
    "\n",
    "* Actions: Automated responses to validation results:\n",
    "  - In this case, automatically updating Data Docs\n",
    "  - Can be extended to include notifications, alerts, or other responses\n",
    "\n",
    "*Note: Think of this as an automated quality control system where:*\n",
    "* Checkpoints act as quality control stations\n",
    "* Actions are the automated responses to inspection results\n",
    "* Together they create a repeatable, automated validation process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Docs Update Action\n",
    "Configure an action to automatically update our documentation site after validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define action to update Data Docs after validation\n",
    "actions = [\n",
    "    gx.checkpoint.actions.UpdateDataDocsAction(\n",
    "        name = \"update_data_docs\",\n",
    "        site_names=[site_name]    # Update our specific validation results site\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Checkpoint\n",
    "Create a checkpoint that combines our validation definition with the update action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a checkpoint that links validations with actions\n",
    "checkpoint_name = \"yellowtaxi_data_validation_checkpoint\"\n",
    "checkpoint = gx.Checkpoint(\n",
    "    name=checkpoint_name,                           # Name for our checkpoint\n",
    "    validation_definitions=[validation_definition], # What to validate\n",
    "    actions=actions                                # What to do after validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Checkpoint to Context\n",
    "Register our checkpoint with the Data Context to make it available for execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the checkpoint to our Data Context\n",
    "checkpoint = context.checkpoints.add(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Checkpoint\n",
    "Run the checkpoint to validate data and trigger the Data Docs update action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the checkpoint and get validation results\n",
    "validation_results = checkpoint.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access Validation Results\n",
    "After checkpoint execution, view the validation results in the auto-generated Data Docs:\n",
    "\n",
    "* Location: `./gx/uncommitted/data_docs/local_site/index.html`\n",
    "* Report Contents:\n",
    "  - Overview of all validations\n",
    "  - Detailed results for each expectation\n",
    "  - Pass/Fail status for data quality rules\n",
    "  - Historical validation results\n",
    "\n",
    "*Note: Open the index.html file in a web browser to view an interactive dashboard of your validation results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Summary and Workflow\n",
    "This notebook demonstrates a complete data validation pipeline using Great Expectations:\n",
    "1. Setup: Configured environment and connected to PostgreSQL\n",
    "2. Expectations: Defined data quality rules for taxi data\n",
    "3. Validations: Executed and verified our quality rules\n",
    "4. Documentation: Generated human-readable reports\n",
    "5. Automation: Set up checkpoints for repeated validation\n",
    "\n",
    "*Note: For detailed documentation and advanced features, refer to [Great Expectations Core (GX Core) Documentation](https://docs.greatexpectations.io/docs/core/introduction/)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gxcore-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
